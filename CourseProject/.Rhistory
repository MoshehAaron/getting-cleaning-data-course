req$created_at
names(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[4,]
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
oauth_endpoints("github")
myapp <- oauth_app("TestingGitHubAPI", "5405f6d506a62a1fbdc9","6fecea8af78cf96bcf639863b71b5f52c0a1d39d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[4,]
repo <- json2[4,]
names(repo)
repo$created_at
## Simple Lattice Plot
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data = airquality)
airquality <- transform(airquality, Month = factor(Month))
xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(5, 1))
p <- xyplot(Ozone ~ Wind, data = airquality)  ## Nothing happens!
print(p)  ## Plot appears
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x + rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x)
xyplot(y ~ x)
xyplot(y ~ x | f, layout = c(2, 1))  ## Plot with 2 panels
xyplot(y ~ x | f, panel = function(x, y, ...) {
panel.xyplot(x, y, ...)  ## First call the default panel function for 'xyplot'
panel.abline(h = median(y), lty = 2)  ## Add a horizontal line at the median
})
xyplot(y ~ x | f, panel = function(x, y, ...) {
panel.xyplot(x, y, ...)  ## First call default panel function
panel.lmline(x, y, col = 2)  ## Overlay a simple linear regression line
})
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
library(datasets)
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(hwy, data= mpg)
qplot(hwy, data = mpg, fill=drv)
qplot(displ, hwy, data = mpg, facets = .~drv)
qplot(displ, hwy, data = mpg, facets = drv~.)
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 2)
?qplot
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 2)
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 8)
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 0.1)
myapp = oauth_app("Sturrion Test",
key="JMHycw5p5RoRTJjwtCQIwx5Yh",
secret="sU1NShIkOxUN3CxVmSBdixjFeNF42oO089iYS5UW5rgr6rRcUB")
library(httr)
myapp = oauth_app("Sturrion Test",
key="JMHycw5p5RoRTJjwtCQIwx5Yh",
secret="sU1NShIkOxUN3CxVmSBdixjFeNF42oO089iYS5UW5rgr6rRcUB")
sig = sign_oauth1.0(myapp,
token = "1852246698-y5XDy6uX6e8NJqkVe9yPwn9OwHAY3HJNyvKhKCR",
token_secret = "ARfNyH24O0xqRhnCu4BAnQ6JFABbyUC8J5f7YXorOi93T")
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json?q=%23freebandnames&since_id=24012619984051000&max_id=250126199840518145&result_type=mixed&count=4", sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json2[1,]
json2[1]
json2[2]
json1
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json?q=adoptadog", sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + geom_smooth()
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
View(X)
X <- X[sample(1:5),]
View(X)
X$var2[c(1,3)] = NA
View(X)
X
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X
X <- X[sample(1:5),]
X
X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[(X$var1 <= 3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
X[which(X$var2 > 8),]
X[(X$var2 > 8),]
X[X$var2 > 8,]
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
X[order(X$var1),]
X[order(X$var1,X$var3),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("./data")){
dir.create("./data")
}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA="ifany")
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212","21213"))
restData[restData$zipCode %in% c("21212","21213"),]
data(UCBAdmissions)
library(datasets)
data(UCBAdmissions)
DF = as.data.frame(
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
xt = xtabs(breaks ~.,data=warpbreaks)
xt
ftable(xt)
head(warpbreaks)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
library(data.table)
install.packages("data.table")
library(data.table)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/', cache=TRUE)
install.packages("fields")
library("BiocInstaller", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("lars")
install.packages("makeslides")
library(data.table)
source("constants.R")
source("createSet.R")
# Create the training set
trainDataSet <- create.set("train")
# Create the test set
testDataSet <- create.set("test")
# Create the total dataset
totalDataSet <- rbind(trainDataSet, testDataSet)
# Cleaning memory
rm(trainDataSet, testDataSet)
setwd("/Users/silvia/Estudiar/Data Science/Courses/Coursera - 03 Getting and Cleaning Data /getting-cleaning-data-course/CourseProject")
library(data.table)
source("constants.R")
source("createSet.R")
# Create the training set
trainDataSet <- create.set("train")
# Create the test set
testDataSet <- create.set("test")
# Create the total dataset
totalDataSet <- rbind(trainDataSet, testDataSet)
# Cleaning memory
rm(trainDataSet, testDataSet)
# Setting column names
source("datasetColumnNames.R")
colnames(totalDataSet) <- dataset.column.names()
cbind(names(totalDataSet))
column.names.table <- cbind(names(totalDataSet))
View(column.names.table)
column.names <- cbind(names(totalDataSet))
column.table <- data.frame(column.names)
column.table <- data.frame(cbind(names(totalDataSet)))
column.table$extract <- grepl("-mean", featuresFile$feature.description)
names(column.table)
column.names <- cbind(names(totalDataSet))
column.table <- data.frame(column.names)
column.table$extract <- grepl("-mean", column.table$column.names)
View(column.table)
column.table$extract <- column.table$extract | grepl("-std", column.table$column.names)
View(column.table)
column.table$extract[1:2,] <- TRUE
View(column.table)
column.table$extract[1:2] <- TRUE
View(column.table)
names(totalDataSet[,column.table$extract])
source("datasetColumnNames.R")
colnames(totalDataSet) <- dataset.column.names()
# Choosing columns to extract
column.names <- cbind(names(totalDataSet))
column.table <- data.frame(column.names)
rm(column.names)
# mean columns
column.table$extract <- grepl("-mean", column.table$column.names)
# std columns
column.table$extract <- column.table$extract | grepl("-std", column.table$column.names)
column.table$extract[1:2] <- TRUE
# get only cols to extract
totalDataSet <- totalDataSet[,column.table$extract])
rm(column.table)
# Setting column names
source("datasetColumnNames.R")
colnames(totalDataSet) <- dataset.column.names()
# Choosing columns to extract
column.names <- cbind(names(totalDataSet))
column.table <- data.frame(column.names)
rm(column.names)
# mean columns
column.table$extract <- grepl("-mean", column.table$column.names)
# std columns
column.table$extract <- column.table$extract | grepl("-std", column.table$column.names)
column.table$extract[1:2] <- TRUE
# get only cols to extract
totalDataSet <- totalDataSet[,column.table$extract]
rm(column.table)
library(data.table)
source("constants.R")
source("create_set.R")
# Create the training set
train.dataset <- create.set("train")
# Create the test set
test.dataset <- create.set("test")
# Create the total dataset
total.dataset <- rbind(train.dataset, test.dataset)
# Cleaning memory
rm(train.dataset, test.dataset)
# Setting column names
source("dataset_columns.R")
colnames(total.dataset) <- dataset.column.names()
# get only cols to extract
new.total.dataset <- extract.columns.dataset(total.dataset)
total.dataset <- extract.columns.dataset(total.dataset)
rm(new.total.dataset)
activity.labels.file.name = paste("activity_labels", file.extension, sep = "")
activity.labels.file <- read.table(paste(data.directory, activity.labels.file.name, sep = path.sep),
sep = " ",
header = FALSE,
col.names = c("activity.id","activity.description"),
colClasses = c("factor","character"))
new.total.dataset <- total.dataset
new.total.dataset$activity.description <- activity.labels.file$activity.description[activity.labels.file$activity.id == new.total.dataset$activity.id]
new.total.dataset$activity.description <- activity.labels.file$activity.description[activity.labels.file$activity.id == new.total.dataset$activity.id,]
new.total.dataset <- merge(activity.labels.file, total.dataset, all=TRUE)
View(new.total.dataset)
names(new.total.dataset)
new.total.dataset <- new.total.dataset[,c(3,2,4:82)]
names(new.total.dataset)
str(new.total.dataset)
new.total.dataset
new.total.dataset$activity.description <- as.factor(new.total.dataset$activity.description)
str(new.total.dataset)
View(new.total.dataset)
summary(total.dataset$activity.id)
summary(new.total.dataset$activity.description)
library(data.table)
source("constants.R")
source("create_set.R")
# Create the training set
train.dataset <- create.set("train")
# Create the test set
test.dataset <- create.set("test")
# Create the total dataset
total.dataset <- rbind(train.dataset, test.dataset)
# Cleaning memory
rm(train.dataset, test.dataset)
# Setting column names
source("dataset_columns.R")
colnames(total.dataset) <- dataset.column.names()
# get only cols to extract
total.dataset <- extract.columns.dataset(total.dataset)
# Use activity names
new.total.dataset <- label.activity.column(total.dataset)
new.total.dataset <- label.activity.column(total.dataset)
summary(new.total.dataset$activity.description)
summary(total.dataset$activity.id)
new.total.dataset <- label.activity.column(total.dataset)
summary(total.dataset$activity.id)
summary(new.total.dataset$activity.description)
View(new.total.dataset)
new.total.dataset <- label.activity.column(total.dataset)
rm(new.total.dataset)
new.total.dataset <- label.activity.column(total.dataset)
rm(new.total.dataset)
new.total.dataset <- label.activity.column(total.dataset)
rm(new.total.dataset)
source("dataset_columns.R")
new.total.dataset <- label.activity.column(total.dataset)
summary(new.total.dataset$activity.description)
summary(total.dataset$activity.id)
tapply(total.dataset$subject.id, total.dataset$activity.id, mean)
?melt
vector.column.names <- names(total.dataset)
vector.column.names <- vector.column.names[3:81]
vector.column.names
dataset.melt <- melt(total.dataset,id=c("subject.id","activity.description"),measure.vars=vector.column.names)
library(reshape2)
dataset.melt <- melt(total.dataset,id=c("subject.id","activity.description"),measure.vars=vector.column.names)
total.dataset <- label.activity.column(total.dataset)
View(total.dataset)
dataset.melt <- melt(total.dataset,id=c("subject.id","activity.description"),measure.vars=vector.column.names)
new.dataset <- dcast(dataset.melt, subject.id + activity.description ~ variable)
new.dataset <- dcast(dataset.melt, subject.id ~ variable)
View(new.dataset)
new.dataset <- dcast(dataset.melt, subject.id + activity.description ~ variable, mean)
View(new.dataset)
?write.table
########################################################################################
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive activity names.
# 5. Creates a second, independent tidy data set with the average of each variable for each
#    activity and each subject.
########################################################################################
library(data.table)
source("constants.R")
source("create_set.R")
# Create the training set
train.dataset <- create.set("train")
# Create the test set
test.dataset <- create.set("test")
# Create the total dataset
total.dataset <- rbind(train.dataset, test.dataset)
# Cleaning memory
rm(train.dataset, test.dataset)
source("dataset_columns.R")
# Setting column names
colnames(total.dataset) <- dataset.column.names()
# get only cols to extract
total.dataset <- extract.columns.dataset(total.dataset)
# Use activity names
total.dataset <- label.activity.column(total.dataset)
# Create the new dataset
library(reshape2)
## Melting data frames
vector.column.names <- names(total.dataset)
vector.column.names <- vector.column.names[3:81]
dataset.melt <- melt(total.dataset,
id=c("subject.id","activity.description"),
measure.vars=vector.column.names)
new.dataset <- dcast(dataset.melt, subject.id + activity.description ~ variable, mean)
new.dataset.file.name = paste("new_dataset", file.extension, sep = "")
write.table(new.dataset,
paste(data.directory, new.dataset.file.name, sep = path.sep))
?write.csv
write.csv(new.dataset, "new.dataset.txt", sep = ",", quote = FALSE)
write.csv(new.dataset, "new.dataset.txt", quote = FALSE)
write.csv(new.dataset, "new.dataset.csv", quote = FALSE)
write.csv(new.dataset, "new.dataset.csv", quote = FALSE)
head(new.dataset)
View(new.dataset)
new.dataset <- new.dataset[order(new.dataset$subject.id, new.dataset$activity.description),]
View(new.dataset)
########################################################################################
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive activity names.
# 5. Creates a second, independent tidy data set with the average of each variable for each
#    activity and each subject.
########################################################################################
library(data.table)
source("constants.R")
source("create_set.R")
# Create the training set
train.dataset <- create.set("train")
# Create the test set
test.dataset <- create.set("test")
# Create the total dataset
total.dataset <- rbind(train.dataset, test.dataset)
# Cleaning memory
rm(train.dataset, test.dataset)
source("dataset_columns.R")
# Setting column names
colnames(total.dataset) <- dataset.column.names()
# get only cols to extract
total.dataset <- extract.columns.dataset(total.dataset)
# Use activity names
total.dataset <- label.activity.column(total.dataset)
?dcast
source("run_analyst.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
run.analysis()
?write.csv
########################################################################################
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive activity names.
# 5. Creates a second, independent tidy data set with the average of each variable for each
#    activity and each subject.
########################################################################################
library(data.table)
# Setting some constant variables and the functions needed
##########################################################
source("constants.R")
source("analysis_functions.R")
# Create a single dataset with train and test datasets
##########################################################
# Create the training set
print("Creating training dataset ...")
train.dataset <- create.set("train")
# Create the test set
print("Creating testing dataset ...")
test.dataset <- create.set("test")
print("Making final dataset ...")
# Create the total dataset
total.dataset <- rbind(train.dataset, test.dataset)
# Cleaning memory
rm(train.dataset, test.dataset)
# Making changes to improve de dataset
##########################################################
# Setting column names
colnames(total.dataset) <- dataset.column.names()
# get only cols to extract
total.dataset <- extract.columns.dataset(total.dataset)
# Use activity names
total.dataset <- label.activity.column(total.dataset)
# Creating and exporting the new dataset
##########################################################
write.csv(create.new.dataset(total.dataset),
"new_dataset.csv",
row.names = FALSE,
quote = FALSE)
print("Done! The new_dataset.csv file is in your working directory.")
new.dataset <- create.new.dataset(total.dataset)
new.dataset[order(new.dataset$subject.id, new.dataset$activity.description),]
new.dataset$subject.id
new.dataset <- create.new.dataset(total.dataset)
?arrange
library(plyr)
?arrange
ordered.dataset <- arrange(new.dataset, subject.id, activity.description)
source("run_analysis.R")
run.analysis()
?write.table
source("run_analysis.R")
run.analysis()
source("run_analysis.R")
run.analysis()
source("run_analysis.R")
run.analysis()
library(data.table)
source("constants.R")
source("analysis_functions.R")
test.dataset <- create.set("test")
test.dataset <- create.set("test")
names(test.dataset)
total.dataset <- test.dataset
colnames(total.dataset) <- dataset.column.names()
total.dataset <- extract.columns.dataset(total.dataset)
names(total.dataset)
write.table(names(total.dataset),campos.txt, quote=FALSE)
write.table(names(total.dataset), "campos.txt", quote=FALSE)
