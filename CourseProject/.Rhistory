# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
req <- GET("https://api.github.com/users/jtleek/datasharing", config(token = github_token))
stop_for_status(req)
content(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
oauth_endpoints("github")
myapp <- oauth_app("TestingGitHubAPI", "5405f6d506a62a1fbdc9","6fecea8af78cf96bcf639863b71b5f52c0a1d39d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/sturrion/repos", config(token = github_token))
stop_for_status(req)
content(req)
table(json2$name, json2$created_at)
table(req$name, req$created_at)
req$name
req$created_at
names(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[4,]
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
oauth_endpoints("github")
myapp <- oauth_app("TestingGitHubAPI", "5405f6d506a62a1fbdc9","6fecea8af78cf96bcf639863b71b5f52c0a1d39d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
content(req)
library(jsonlite)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[4,]
repo <- json2[4,]
names(repo)
repo$created_at
## Simple Lattice Plot
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data = airquality)
airquality <- transform(airquality, Month = factor(Month))
xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(5, 1))
p <- xyplot(Ozone ~ Wind, data = airquality)  ## Nothing happens!
print(p)  ## Plot appears
set.seed(10)
x <- rnorm(100)
f <- rep(0:1, each = 50)
y <- x + f - f * x + rnorm(100, sd = 0.5)
f <- factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x)
xyplot(y ~ x)
xyplot(y ~ x | f, layout = c(2, 1))  ## Plot with 2 panels
xyplot(y ~ x | f, panel = function(x, y, ...) {
panel.xyplot(x, y, ...)  ## First call the default panel function for 'xyplot'
panel.abline(h = median(y), lty = 2)  ## Add a horizontal line at the median
})
xyplot(y ~ x | f, panel = function(x, y, ...) {
panel.xyplot(x, y, ...)  ## First call default panel function
panel.lmline(x, y, col = 2)  ## Overlay a simple linear regression line
})
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
library(datasets)
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(hwy, data= mpg)
qplot(hwy, data = mpg, fill=drv)
qplot(displ, hwy, data = mpg, facets = .~drv)
qplot(displ, hwy, data = mpg, facets = drv~.)
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 2)
?qplot
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 2)
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 8)
qplot(displ, hwy, data = mpg, facets = drv~., binwidth = 0.1)
myapp = oauth_app("Sturrion Test",
key="JMHycw5p5RoRTJjwtCQIwx5Yh",
secret="sU1NShIkOxUN3CxVmSBdixjFeNF42oO089iYS5UW5rgr6rRcUB")
library(httr)
myapp = oauth_app("Sturrion Test",
key="JMHycw5p5RoRTJjwtCQIwx5Yh",
secret="sU1NShIkOxUN3CxVmSBdixjFeNF42oO089iYS5UW5rgr6rRcUB")
sig = sign_oauth1.0(myapp,
token = "1852246698-y5XDy6uX6e8NJqkVe9yPwn9OwHAY3HJNyvKhKCR",
token_secret = "ARfNyH24O0xqRhnCu4BAnQ6JFABbyUC8J5f7YXorOi93T")
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json?q=%23freebandnames&since_id=24012619984051000&max_id=250126199840518145&result_type=mixed&count=4", sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json2[1,]
json2[1]
json2[2]
json1
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json?q=adoptadog", sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + geom_smooth()
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
View(X)
X <- X[sample(1:5),]
View(X)
X$var2[c(1,3)] = NA
View(X)
X
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X
X <- X[sample(1:5),]
X
X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[(X$var1 <= 3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
X[which(X$var2 > 8),]
X[(X$var2 > 8),]
X[X$var2 > 8,]
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
X[order(X$var1),]
X[order(X$var1,X$var3),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("./data")){
dir.create("./data")
}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA="ifany")
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212","21213"))
restData[restData$zipCode %in% c("21212","21213"),]
data(UCBAdmissions)
library(datasets)
data(UCBAdmissions)
DF = as.data.frame(
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
xt = xtabs(breaks ~.,data=warpbreaks)
xt
ftable(xt)
head(warpbreaks)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
library(data.table)
install.packages("data.table")
library(data.table)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/', cache=TRUE)
install.packages("fields")
library("BiocInstaller", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("lars")
install.packages("makeslides")
?read.fwf
########################################################################################
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive activity names.
# 5. Creates a second, independent tidy data set with the average of each variable for each
#    activity and each subject.
########################################################################################
library(data.table)
dataDirectory <- "./UCI HAR Dataset"
pathSep <- "/"
## Loading activities
activityLabelsFile <- read.table(paste(dataDirectory, "activity_labels.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("activity.id","activity.description"),
colClasses = c("factor","character"))
## Loading features
featuresFile <- read.table(paste(dataDirectory, "features.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("feature.id","feature.description"),
colClasses = c("factor","character"))
# Reading the training set
trainDirectory <- "/train"
#xTrain <- read.fwf("./UCI HAR Dataset/train/X_train.txt",
#                   rep(16, times=561),
#                   header = FALSE,
#                   col.names = featuresFile$feature.description,
#                   colClasses = "numeric")
# Reading the testing set
testDirectory <- "test"
# Subject
testSubject <- read.table(paste(dataDirectory, testDirectory, "subject_test.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("subject.id"),
colClasses = "factor")
testActivities <- read.table(paste(dataDirectory, testDirectory, "y_test.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("activity.id"),
colClasses = "factor")
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
n = 50)
# Merges the training and the test sets to create one data set.
#write.csv(oneRow, "./UCI HAR Dataset/train/oneRow.csv", sep=",")
setwd("/Users/silvia/Estudiar/Data Science/Courses/Coursera - 03 Getting and Cleaning Data /getting-cleaning-data-course/CourseProject")
########################################################################################
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive activity names.
# 5. Creates a second, independent tidy data set with the average of each variable for each
#    activity and each subject.
########################################################################################
library(data.table)
dataDirectory <- "./UCI HAR Dataset"
pathSep <- "/"
## Loading activities
activityLabelsFile <- read.table(paste(dataDirectory, "activity_labels.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("activity.id","activity.description"),
colClasses = c("factor","character"))
## Loading features
featuresFile <- read.table(paste(dataDirectory, "features.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("feature.id","feature.description"),
colClasses = c("factor","character"))
# Reading the training set
trainDirectory <- "/train"
#xTrain <- read.fwf("./UCI HAR Dataset/train/X_train.txt",
#                   rep(16, times=561),
#                   header = FALSE,
#                   col.names = featuresFile$feature.description,
#                   colClasses = "numeric")
# Reading the testing set
testDirectory <- "test"
# Subject
testSubject <- read.table(paste(dataDirectory, testDirectory, "subject_test.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("subject.id"),
colClasses = "factor")
testActivities <- read.table(paste(dataDirectory, testDirectory, "y_test.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("activity.id"),
colClasses = "factor")
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
n = 50)
# Merges the training and the test sets to create one data set.
#write.csv(oneRow, "./UCI HAR Dataset/train/oneRow.csv", sep=",")
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
n = 100)
rm(xTest)
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
n = 100)
rm(xTest)
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
n = 500)
library(data.table)
dataDirectory <- "./UCI HAR Dataset"
pathSep <- "/"
featuresFile <- read.table(paste(dataDirectory, "features.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("feature.id","feature.description"),
colClasses = c("factor","character"))
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
buffersize = 100,
n = 500)
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
buffersize = 100,
n = 1000)
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
buffersize = 100)
xTest <- read.fwf("./UCI HAR Dataset/test/X_test.txt",
rep(16, times=561),
header = FALSE,
col.names = featuresFile$feature.description,
colClasses = "numeric",
buffersize = 200)
featuresFile[featuresFile$feature.description in %mean%,]
?in
featuresFile[featuresFile$feature.description %in% %mean%,]
featuresFile[featuresFile$feature.description %in% "mean",]
featuresFile[featuresFile$feature.description %in% "Mean",]
featuresFile$feature.description %in% "Mean"
View(featuresFile)
featuresFile$feature.description %in% "mean"
pmatch("m",   c("mean", "median")
)
pmatch(featuresFile$feature.description, c("-mean","-std"))
pmatch("-mean", featuresFile$feature.description))
pmatch("-mean", featuresFile$feature.description)
charmatch("-mean", featuresFile$feature.description)
grepl("-mean", featuresFile$feature.description)
featuresFile <- read.table(paste(dataDirectory, "features.txt", sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("feature.id","feature.description"),
colClasses = c("factor","character"))
featuresFile$isMeanCol <- grepl("-mean", featuresFile$feature.description)
featuresFile$isStdCol <- grepl("-std", featuresFile$feature.description)
featuresFile$toExtract <- featuresFile$isMeanCol | featuresFile$isStdCol
View(featuresFile)
featuresFile[featuresFile$toExtract==TRUE,]
nrow(featuresFile[featuresFile$toExtract==TRUE,])
library(data.table)
set.type <- "test"
data.directory <- "./UCI HAR Dataset"
path.sep <- "/"
file.extension <- ".txt"
## Check that set.type is valid
if (!set.type %in% c("train","test") {
stop("invalid set.type. It must be train or test")
}
# Subject
subjects.file.name = paste("subject_", set.type, file.extension, sep = "")
subjects <- read.table(paste(data.directory, set.type, subject.file.name, sep = path.sep),
#sep = " ",
header = FALSE,
col.names = c("subject.id"),
colClasses = "factor")
library(data.table)
set.type <- "test"
data.directory <- "./UCI HAR Dataset"
path.sep <- "/"
file.extension <- ".txt"
path.sep <- "/"
file.extension <- ".txt"
ls()
getwd()
source("createSet.R")
source("createSet.R")
create.set("test")
source("createSet.R")
create.set("test")
source("createSet.R")
create.set("test")
source("createSet.R")
create.set("test")
source("createSet.R")
create.set("test")
source("createSet.R")
create.set("test")
source("createSet.R")
create.set("test")
result <- create.set("test")
source("createSet.R")
result <- create.set("test")
View(result)
summary(result)
source("createSet.R")
result <- create.set("test")
summary(result)
getwd()
source("createSet.R")
result <- create.set("test")
ls()
ls(all = TRUE)
source("createSet.R")
source("createSet.R")
result <- create.set("test")
head(result, 1)
source("createSet.R")
result <- create.set("test")
head(result, 1)
names(result)
library(data.table)
source("createSet.R")
trainDataSet <- create.set("train")
testDataSet <- create.set("test")
totalDataSet <- rbind(trainDataSet, testDataSet)
rm(trainDataSet, testDataSet)
?rbin
?rbind
source("constants.R")
library(data.table)
source("constants.R")
source("createSet.R")
# Create the sets
trainDataSet <- create.set("train")
testDataSet <- create.set("test")
# 1. Merges the training and the test sets to create one data set.
totalDataSet <- rbind(trainDataSet, testDataSet)
rm(trainDataSet, testDataSet)
# Loading features
features.file.name = paste("features", file.extension, sep = "")
features.file <- read.table(paste(data.directory, features.file.name, sep = pathSep),
sep = " ",
header = FALSE,
col.names = c("feature.id","feature.description"),
colClasses = c("factor","character"))
colnames(totalDataSet) <- cbind("subject.id", "activity.id", features.file$feature.desciption)
features.file.name = paste("features", file.extension, sep = "")
features.file <- read.table(paste(data.directory, features.file.name, sep = path.sep),
sep = " ",
header = FALSE,
col.names = c("feature.id","feature.description"),
colClasses = c("factor","character"))
colnames(totalDataSet) <- cbind("subject.id", "activity.id", features.file$feature.description)
colnames(totalDataSet) <- c("subject.id", "activity.id", features.file$feature.description)
names(totalDataSet)
library(data.table)
source("constants.R")
source("createSet.R")
# Create the sets
trainDataSet <- create.set("train")
testDataSet <- create.set("test")
# 1. Merges the training and the test sets to create one data set.
totalDataSet <- rbind(trainDataSet, testDataSet)
rm(trainDataSet, testDataSet)
# Setting column names
source("datasetColumnNames.R")
colnames(totalDataSet) <- dataset.column.names()
names(totalDataSet)
column.names.table <- data.frame(names(totalDataSet))
column.names.table <- cbind(names(totalDataSet))
column.names.table <- data.frame()
column.names.table$columnName <- cbind(names(totalDataSet))
column.names.table$columnName <-names(totalDataSet)
